{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-18T12:09:08.070506600Z",
     "start_time": "2026-01-18T12:09:07.506411800Z"
    }
   },
   "source": [
    "from fontTools.misc.classifyTools import Classifier\n",
    "from sympy.tensor.tensor import tensor_mul\n",
    "\n",
    "classification_nmaes={\n",
    "    0: '上衣',\n",
    "    1: '鞋子',\n",
    "    2: '包',\n",
    "    3: '下衣',\n",
    "    4: '手表',\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:09:11.991996800Z",
     "start_time": "2026-01-18T12:09:08.071506400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def sorted_alphanumeric(data):\n",
    "    import re\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(data, key=alphanum_key)\n",
    "\n",
    "#定义自定义数据集类FolderDataset\n",
    "class FolderDataset(Dataset):\n",
    "    def __init__(self,main_dir,transform=None):\n",
    "        self.root_dir=main_dir\n",
    "        self.transform=transform\n",
    "        self.all_image=sorted_alphanumeric(os.listdir(main_dir))\n",
    "        self.classification_nmaes=pd.read_csv('common/fashion-labels.csv')\n",
    "        self.laberl_dict=dict(zip(self.classification_nmaes['id'],self.classification_nmaes['target']))\n",
    "    def __len__(self):\n",
    "        return len(self.all_image)\n",
    "    def __getitem__(self,idx):\n",
    "        img_loc=os.path.join(self.root_dir,self.all_image[idx])\n",
    "\n",
    "        image=Image.open(img_loc).convert('RGB')\n",
    "        img_flag_id=self.labell_dict[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image=self.transform(image)\n",
    "        else:\n",
    "            raise RuntimeError(\"Transform is not defined\")\n",
    "        return tensor_image,img_flag_id\n"
   ],
   "id": "705fbfa9c24f6801",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:09:12.700689500Z",
     "start_time": "2026-01-18T12:09:11.999003900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "#检查是否有可用的GPU,否则使用CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "transforms=T.Compose([\n",
    "    T.Resize((64,64)),\n",
    "    T.ToTensor(),\n",
    "\n",
    "])\n",
    "print('----------正在创建数据表----------')\n",
    "full_dataset=FolderDataset('common/dataset/',transform=transforms)\n",
    "train_size=int(0.75*len(full_dataset))\n",
    "val_size=len(full_dataset)-train_size\n",
    "full_dataset,val_size=torch.utils.data.random_split(full_dataset,[train_size,val_size])\n",
    "\n",
    "\n",
    "print('----------数据表创建完成----------')\n",
    "print('----------正在创建数据加载器----------')\n",
    "\n",
    "#定义批次大小\n",
    "batch=32\n",
    "\n",
    "#创建训练集的DataLoder,批次大小为32\n",
    "train_loder=torch.utils.data.DataLoader(full_dataset,batch_size=batch,shuffle=True)\n",
    "#创建验证集的DataLoder,批次大小为32\n",
    "val_loader=torch.utils.data.DataLoader(val_size,batch_size=batch)\n",
    "\n",
    "#创建完整集的DataLoder,批次大小为32\n",
    "full_loder=torch.utils.data.DataLoader(full_dataset,batch_size=batch)\n",
    "\n",
    "print('----------数据加载器创建完成----------')\n",
    "\n",
    "#遍历训练集的DataLoder，打印每第一个批次的数据\n",
    "for x,y in train_loder:\n",
    "    print('图像张量形状:',x.shape)\n",
    "    print('标签:',y.shape)\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "7e806f90f07b41a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------正在创建数据表----------\n",
      "----------数据表创建完成----------\n",
      "----------正在创建数据加载器----------\n",
      "----------数据加载器创建完成----------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FolderDataset' object has no attribute 'labell_dict'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 38\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m----------数据加载器创建完成----------\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m#遍历训练集的DataLoder，打印每第一个批次的数据\u001B[39;00m\n\u001B[1;32m---> 38\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x,y \u001B[38;5;129;01min\u001B[39;00m train_loder:\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m图像张量形状:\u001B[39m\u001B[38;5;124m'\u001B[39m,x\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m标签:\u001B[39m\u001B[38;5;124m'\u001B[39m,y\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Smart_Treasure_Hunt\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    731\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    732\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    733\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 734\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    735\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    736\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    737\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    738\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    739\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    740\u001B[0m ):\n",
      "File \u001B[1;32m~\\.conda\\envs\\Smart_Treasure_Hunt\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    788\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    789\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 790\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    791\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    792\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Smart_Treasure_Hunt\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[1;32m---> 50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[1;32m~\\.conda\\envs\\Smart_Treasure_Hunt\\lib\\site-packages\\torch\\utils\\data\\dataset.py:416\u001B[0m, in \u001B[0;36mSubset.__getitems__\u001B[1;34m(self, indices)\u001B[0m\n\u001B[0;32m    414\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    415\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 416\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx]] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[1;32m~\\.conda\\envs\\Smart_Treasure_Hunt\\lib\\site-packages\\torch\\utils\\data\\dataset.py:416\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    414\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    415\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 416\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "Cell \u001B[1;32mIn[2], line 28\u001B[0m, in \u001B[0;36mFolderDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     25\u001B[0m img_loc\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot_dir,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mall_image[idx])\n\u001B[0;32m     27\u001B[0m image\u001B[38;5;241m=\u001B[39mImage\u001B[38;5;241m.\u001B[39mopen(img_loc)\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 28\u001B[0m img_flag_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabell_dict\u001B[49m[idx]\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform:\n\u001B[0;32m     31\u001B[0m     image\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(image)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'FolderDataset' object has no attribute 'labell_dict'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationModel,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=8,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
    "        self.pool=nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "        self.conv2=nn.Conv2d(in_channels=8,out_channels=16,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
    "        self.fc1=nn.Linear(16*16*16,128)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(x)\n",
    "\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=self.pool(x)\n",
    "\n",
    "        x=x.reshape(x.shape[0],-1)\n",
    "\n",
    "        x=self.fc1(x)\n",
    "        x=F.log_softmax(x,dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# 实例化CNN模型\n",
    "model=ClassificationModel()\n",
    "\n",
    "print(model)\n",
    "\n",
    "#获取训练加载器的迭代器\n",
    "train_iterator=iter(train_loder)\n",
    "#获取下一个批次的数据\n",
    "images,labels=next(train_iterator)\n",
    "print('数据经过模型后向前传递后的维度:',model(images).shape)"
   ],
   "id": "53f294ad1b8a4554",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
