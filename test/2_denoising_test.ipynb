{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-16T15:38:44.601330300Z",
     "start_time": "2026-01-16T15:38:44.560330800Z"
    }
   },
   "source": [
    "\n",
    "from pprint import pprint\n",
    "from re import T\n",
    "import torchvision.transforms as transforms  #图像预处理工具\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import axes\n",
    "from sympy import true\n",
    "from torchvision.datasets import ImageFolder\n",
    "from click.core import batch\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "from torch.distributions import transform_to\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.xpu import device\n"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T15:38:44.634331500Z",
     "start_time": "2026-01-16T15:38:44.603331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#自定义数据类型\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.main_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_names=os.listdir(image_dir)  #获取目录下所有文件名\n",
    "        self.image_filenames = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "#传入图片id，获取数据元素\n",
    "    def __getitem__(self, idx):\n",
    "        #根据索引号，构建图片的完整路径\n",
    "        img_loc= os.path.join(self.main_dir, self.image_filenames[idx])\n",
    "        image = Image.open(img_loc).convert('RGB')\n",
    "\n",
    "        #利用transform转换成tensor\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        #抛出异常\n",
    "        else:\n",
    "            raise ValueError(\"Transform is not defined\")\n",
    "\n",
    "        #向原始图像中增加随机噪声\n",
    "        noisy_factor = 0.5\n",
    "        noisy_image = image + noisy_factor * torch.randn(*image.shape)\n",
    "        noisy_image = torch.clamp(noisy_image, 0., 1.)\n",
    "#返回噪声图片和原始图片\n",
    "        return noisy_image, image\n",
    "\n",
    "\n"
   ],
   "id": "6f6670bff3d39baa",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T15:38:44.703166800Z",
     "start_time": "2026-01-16T15:38:44.650331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.transforms import Compose\n",
    "import torchvision.transforms as transforms  #图像预处理工具\n",
    " #测试主流程\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((68,68)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "#写代码时没有注意到中括号\n",
    "\n",
    "#创建数据集\n",
    "full_dataset=ImageDataset(image_dir ='../common/dataset/', transform=transform)\n",
    "\n",
    "print(len(full_dataset))\n"
   ],
   "id": "83493b49b4c01efe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24853\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T15:38:44.732167Z",
     "start_time": "2026-01-16T15:38:44.704166200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "#划分数据集\n",
    "#train_dataset, test_dataset = random_split(full_dataset[0.75,0.25])\n",
    "train_dataset, test_dataset = random_split(full_dataset, [0.75, 0.25])\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ],
   "id": "b6b75a1f323c2efe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18640\n",
      "6213\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T15:38:44.748179300Z",
     "start_time": "2026-01-16T15:38:44.734167200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#创建dataLoder\n",
    "batch_size=64\n",
    "train_loder=DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    "\n",
    ")"
   ],
   "id": "95dd4470bda7221a",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T15:38:44.778165800Z",
     "start_time": "2026-01-16T15:38:44.750166900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loder=DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "\n",
    ")"
   ],
   "id": "168d9c40b26ac9fb",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T15:38:45.527127700Z",
     "start_time": "2026-01-16T15:38:44.779166100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for x,y in train_loder:\n",
    "   print(f\"x: {x}, x shape: {x.shape}, x device: {x.device}\")\n",
    "   print(f\"y: {y}, y shape: {y.shape}, y device: {y.device}\")\n",
    "   break"
   ],
   "id": "92285a5386c7cff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[[1.0000, 1.0000, 0.4207,  ..., 0.6925, 0.4715, 0.1095],\n",
      "          [0.8190, 1.0000, 0.5193,  ..., 0.5236, 0.5242, 1.0000],\n",
      "          [0.2606, 0.6831, 0.2847,  ..., 0.2032, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.8317, 1.0000, 0.4683,  ..., 1.0000, 0.2668, 1.0000],\n",
      "          [1.0000, 0.7080, 1.0000,  ..., 1.0000, 1.0000, 0.9963],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[1.0000, 0.2627, 0.8472,  ..., 1.0000, 1.0000, 0.6547],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.2744, 0.4890, 0.8258],\n",
      "          [0.7420, 1.0000, 0.6970,  ..., 1.0000, 0.9862, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 0.7487,  ..., 1.0000, 0.8059, 0.9746],\n",
      "          [1.0000, 0.0436, 1.0000,  ..., 0.0000, 0.2334, 0.5922],\n",
      "          [1.0000, 0.0286, 0.9560,  ..., 0.9411, 1.0000, 0.5546]],\n",
      "\n",
      "         [[0.7559, 1.0000, 0.9247,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.4639, 1.0000, 0.5237,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 0.7954,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.4099, 0.3571],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.5515],\n",
      "          [0.4731, 0.3038, 1.0000,  ..., 0.7137, 1.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 0.0000, 1.0000, 1.0000],\n",
      "          [0.9142, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.4649, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.1290],\n",
      "          ...,\n",
      "          [0.5030, 1.0000, 0.0000,  ..., 0.7588, 0.3383, 0.4043],\n",
      "          [1.0000, 1.0000, 0.2615,  ..., 1.0000, 0.8738, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[1.0000, 0.7304, 1.0000,  ..., 1.0000, 0.8959, 1.0000],\n",
      "          [0.6309, 0.8143, 1.0000,  ..., 0.0772, 0.4712, 1.0000],\n",
      "          [1.0000, 0.6354, 0.7898,  ..., 1.0000, 1.0000, 0.3670],\n",
      "          ...,\n",
      "          [0.2588, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 0.4444,  ..., 0.3201, 1.0000, 0.6821],\n",
      "          [1.0000, 1.0000, 0.7894,  ..., 0.6032, 1.0000, 0.9638]],\n",
      "\n",
      "         [[0.7171, 0.9091, 0.6525,  ..., 1.0000, 1.0000, 0.5900],\n",
      "          [1.0000, 0.6304, 1.0000,  ..., 0.8697, 0.7191, 1.0000],\n",
      "          [0.7951, 0.6914, 1.0000,  ..., 1.0000, 0.0000, 0.6405],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 0.8162,  ..., 0.2193, 1.0000, 0.3918],\n",
      "          [1.0000, 0.8450, 1.0000,  ..., 0.6928, 0.5282, 1.0000],\n",
      "          [1.0000, 0.8405, 0.8218,  ..., 1.0000, 1.0000, 0.5693]]],\n",
      "\n",
      "\n",
      "        [[[0.9416, 0.9441, 1.0000,  ..., 0.9209, 0.8238, 1.0000],\n",
      "          [0.4008, 0.6600, 0.7208,  ..., 0.7967, 1.0000, 1.0000],\n",
      "          [1.0000, 0.2973, 0.8671,  ..., 1.0000, 1.0000, 0.5208],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 0.8985,  ..., 1.0000, 1.0000, 0.3512],\n",
      "          [0.2453, 0.7293, 0.7683,  ..., 0.9071, 0.6431, 0.0874],\n",
      "          [0.6500, 1.0000, 0.2909,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[0.9467, 1.0000, 1.0000,  ..., 0.4307, 1.0000, 0.4897],\n",
      "          [0.3564, 0.7849, 1.0000,  ..., 1.0000, 0.7245, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.8390, 1.0000, 0.9723],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.9627, 1.0000, 1.0000],\n",
      "          [1.0000, 0.6456, 0.7476,  ..., 0.9423, 0.9575, 0.3474],\n",
      "          [0.5209, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9996]],\n",
      "\n",
      "         [[1.0000, 0.5546, 0.5778,  ..., 1.0000, 0.8945, 0.6800],\n",
      "          [1.0000, 0.6051, 0.8593,  ..., 1.0000, 0.1716, 0.8719],\n",
      "          [0.7847, 0.8079, 0.5757,  ..., 0.6133, 1.0000, 0.9387],\n",
      "          ...,\n",
      "          [0.7733, 0.8095, 1.0000,  ..., 0.6612, 0.4415, 1.0000],\n",
      "          [0.7512, 0.3801, 0.8282,  ..., 0.9143, 0.8667, 1.0000],\n",
      "          [0.5959, 1.0000, 0.6451,  ..., 0.9194, 1.0000, 0.5873]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.3269, 1.0000, 0.4908,  ..., 1.0000, 0.4684, 0.7535],\n",
      "          [0.9133, 1.0000, 0.8312,  ..., 0.4204, 0.5293, 0.4881],\n",
      "          [1.0000, 0.3390, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 0.4250, 0.4340,  ..., 0.6409, 0.3249, 0.9661],\n",
      "          [0.6413, 0.5702, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 0.9126,  ..., 1.0000, 0.7141, 1.0000]],\n",
      "\n",
      "         [[0.3007, 0.5938, 0.0918,  ..., 0.9365, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.9935, 0.7446],\n",
      "          [0.4817, 0.9390, 1.0000,  ..., 0.3316, 1.0000, 0.2964],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.6767, 1.0000],\n",
      "          [0.8790, 1.0000, 1.0000,  ..., 0.9339, 0.4487, 1.0000],\n",
      "          [1.0000, 0.7845, 0.8902,  ..., 0.3757, 1.0000, 1.0000]],\n",
      "\n",
      "         [[0.3060, 1.0000, 1.0000,  ..., 0.9052, 0.6551, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.8161, 1.0000, 1.0000,  ..., 0.4739, 0.6643, 1.0000],\n",
      "          ...,\n",
      "          [0.5175, 0.2041, 0.7317,  ..., 0.3340, 1.0000, 1.0000],\n",
      "          [1.0000, 0.4965, 0.9610,  ..., 0.4259, 1.0000, 1.0000],\n",
      "          [0.4465, 1.0000, 1.0000,  ..., 0.6512, 1.0000, 0.9430]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 0.5244,  ..., 1.0000, 0.9771, 1.0000],\n",
      "          [1.0000, 0.5274, 1.0000,  ..., 0.8476, 1.0000, 1.0000],\n",
      "          [0.0600, 1.0000, 0.0000,  ..., 0.3516, 0.6486, 0.5805],\n",
      "          ...,\n",
      "          [1.0000, 0.5832, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 0.9703, 0.5647,  ..., 1.0000, 0.6490, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.6204, 0.9749, 1.0000]],\n",
      "\n",
      "         [[1.0000, 1.0000, 0.3707,  ..., 1.0000, 1.0000, 0.7953],\n",
      "          [0.8137, 0.8439, 0.4696,  ..., 0.9439, 0.1428, 1.0000],\n",
      "          [0.1046, 1.0000, 0.8775,  ..., 1.0000, 1.0000, 0.5176],\n",
      "          ...,\n",
      "          [1.0000, 0.9032, 1.0000,  ..., 1.0000, 0.7212, 1.0000],\n",
      "          [1.0000, 0.9824, 0.6135,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.7239, 0.9502, 0.9260,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[0.8326, 1.0000, 1.0000,  ..., 0.4541, 0.4658, 1.0000],\n",
      "          [1.0000, 0.3564, 0.4601,  ..., 1.0000, 1.0000, 0.2651],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.3218, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.8265, 1.0000, 0.5761],\n",
      "          [0.3541, 1.0000, 0.9576,  ..., 0.6797, 1.0000, 1.0000],\n",
      "          [0.0000, 1.0000, 1.0000,  ..., 1.0000, 0.1272, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 0.1750, 0.9602, 0.7763],\n",
      "          [0.2754, 1.0000, 0.1945,  ..., 1.0000, 1.0000, 0.6636],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.6495, 0.7775],\n",
      "          ...,\n",
      "          [0.5913, 1.0000, 0.8983,  ..., 0.1226, 1.0000, 0.0000],\n",
      "          [1.0000, 1.0000, 0.4367,  ..., 1.0000, 0.3083, 1.0000],\n",
      "          [0.7986, 1.0000, 0.4142,  ..., 0.5668, 1.0000, 1.0000]],\n",
      "\n",
      "         [[1.0000, 0.1082, 0.6448,  ..., 1.0000, 0.4443, 1.0000],\n",
      "          [1.0000, 0.9068, 1.0000,  ..., 0.3287, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.5932, 1.0000],\n",
      "          ...,\n",
      "          [0.5767, 1.0000, 1.0000,  ..., 0.6769, 1.0000, 0.8746],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.6232, 1.0000, 0.8340],\n",
      "          [0.7131, 1.0000, 0.1199,  ..., 1.0000, 1.0000, 0.5225]],\n",
      "\n",
      "         [[1.0000, 1.0000, 0.0000,  ..., 0.3434, 0.4850, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.0000, 0.7886, 0.9157],\n",
      "          [0.5409, 0.3321, 0.4360,  ..., 1.0000, 0.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 0.2138, 1.0000,  ..., 1.0000, 0.9978, 0.5527],\n",
      "          [0.3489, 1.0000, 0.7720,  ..., 1.0000, 0.2271, 0.5873],\n",
      "          [0.8527, 1.0000, 1.0000,  ..., 0.9983, 1.0000, 1.0000]]]]), x shape: torch.Size([64, 3, 68, 68]), x device: cpu\n",
      "y: tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]]), y shape: torch.Size([64, 3, 68, 68]), y device: cpu\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T15:38:45.588126200Z",
     "start_time": "2026-01-16T15:38:45.532126900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''from torch._refs import nn\n",
    "\n",
    "\n",
    "#定义神经网络结构类\n",
    "class ConvDenoiser(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvDenoiser,self).__init__()\n",
    "        #编码器\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride =1,padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride =1,padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride =1,padding=1)\n",
    "        self.pool =nn.MaxPool( 2,2)\n",
    "        #解码器\n",
    "        self.t_conv1 = nn.ConvTranspose2d(8,8,kernel_size=3,stride=2,padding=1)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(8,16,kernel_size=3,stride=2,padding=1)\n",
    "         self.t_conv3= nn.ConvTranspose2d(16,32,kernel_size=3,stride=2,padding=1)\n",
    "         self.conv_out= nn.Conv2d(32,3,3,padding=1)\n",
    "\n",
    "def forward(self, x):\n",
    "\n",
    "#编码\n",
    "        x = torch.relu(self.t_conv1(x))\n",
    "        print('conv1 shape:',x.shape)\n",
    "        x = self.pool(x)\n",
    "        print('pool1 shape:',x.shape)\n",
    "\n",
    "        x = torch.relu(self.t_conv2(x))\n",
    "        print('conv2 shape:',x.shape)\n",
    "        x = self.pool(x)\n",
    "        print('pool2 shape:',x.shape)\n",
    "\n",
    "        x = torch.relu(self.t_conv3(x))\n",
    "        print('conv3 shape:',x.shape)\n",
    "        x = self.pool(x)\n",
    "        print('pool3 shape:',x.shape)\n",
    "\n",
    "#解码\n",
    "       x=torch.relu(self.conv1(x))\n",
    "       print('conv1 shape:',x.shape)\n",
    "\n",
    "        x=torch.relu(self.conv2(x))\n",
    "       print('conv2 shape:',x.shape)\n",
    "\n",
    "        x=torch.relu(self.conv3(x))\n",
    "       print('conv3 shape:',x.shape)\n",
    "\n",
    "       x=torch.sigmoid(self.conv_out(x))\n",
    "       print('conv_out  shape:',x.shape)\n",
    "\n",
    "       return  x\n",
    "\n",
    "\n",
    "model = ConvDenoiser()\n",
    "print(model)\n",
    "\n",
    "x = torch.forward(torch.rand(1,3,68,68))\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvDenoiser(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvDenoiser, self).__init__()\n",
    "        # 编码层定义（示例，你可以根据需求调整通道数和核大小）\n",
    "        self.t_conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.t_conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.t_conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 池化层\n",
    "\n",
    "        # 解码层定义（注意通道数要和编码对应）\n",
    "        self.conv1 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 3, kernel_size=3, padding=1)\n",
    "        self.conv_out = nn.Conv2d(3, 3, kernel_size=3, padding=1)  # 输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 编码\n",
    "        x = torch.relu(self.t_conv1(x))\n",
    "        print('conv1 shape:',x.shape)\n",
    "        x = self.pool(x)\n",
    "        print('pool1 shape:',x.shape)\n",
    "\n",
    "        x = torch.relu(self.t_conv2(x))\n",
    "        print('conv2 shape:',x.shape)\n",
    "        x = self.pool(x)\n",
    "        print('pool2 shape:',x.shape)\n",
    "\n",
    "        x = torch.relu(self.t_conv3(x))\n",
    "        print('conv3 shape:',x.shape)\n",
    "        x = self.pool(x)\n",
    "        print('pool3 shape:',x.shape)\n",
    "\n",
    "        # 解码（缩进和编码部分保持一致）\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        print('conv1 shape:',x.shape)\n",
    "\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        print('conv2 shape:',x.shape)\n",
    "\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        print('conv3 shape:',x.shape)\n",
    "\n",
    "        x = torch.sigmoid(self.conv_out(x))\n",
    "        print('conv_out  shape:',x.shape)\n",
    "\n",
    "        return x\n",
    "\n",
    "# 实例化模型并测试\n",
    "model = ConvDenoiser()\n",
    "print(model)\n",
    "\n",
    "# 生成测试输入 [batch_size, channels, height, width]\n",
    "test_input = torch.rand(1, 3, 68, 68)\n",
    "# 正确调用 forward 方法\n",
    "output = model(test_input)  # 等价于 model.forward(test_input)\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "efe74a7d5358895e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvDenoiser(\n",
      "  (t_conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (t_conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (t_conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_out): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "conv1 shape: torch.Size([1, 32, 68, 68])\n",
      "pool1 shape: torch.Size([1, 32, 34, 34])\n",
      "conv2 shape: torch.Size([1, 64, 34, 34])\n",
      "pool2 shape: torch.Size([1, 64, 17, 17])\n",
      "conv3 shape: torch.Size([1, 128, 17, 17])\n",
      "pool3 shape: torch.Size([1, 128, 8, 8])\n",
      "conv1 shape: torch.Size([1, 64, 8, 8])\n",
      "conv2 shape: torch.Size([1, 32, 8, 8])\n",
      "conv3 shape: torch.Size([1, 3, 8, 8])\n",
      "conv_out  shape: torch.Size([1, 3, 8, 8])\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T15:38:45.613125600Z",
     "start_time": "2026-01-16T15:38:45.590126100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#指定损失函数\n",
    "criterion = nn.MSELoss()\n",
    "#指定优化器\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "99a10ab99ab1299d",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T06:03:39.443646900Z",
     "start_time": "2026-01-17T06:03:38.379744100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#创建数据集\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "\n",
    "#检查是否有可用的GPU，有则使用GPU，否则用CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "#定义数据预处理\n",
    "transforms=T.Compose([\n",
    "    T.Resize((68,68)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "print(\"--------------正在创建的数据集------------\")\n",
    "\n",
    "#创建数据集\n",
    "\n",
    "\n",
    "full_dataset=ImageDataset(image_dir ='../common/dataset/', transform=transform)\n",
    "\n",
    "#计算训练集和验证集的大小\n",
    "train_size = int(0.75 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "\n",
    "#按照计算的数据大小，随机划分训练集和验证集\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "#设置训练书记的批次大小\n",
    "batch_size=32\n",
    "\n",
    "print('数据集创建完成，正在创建数据加载器...')\n",
    "\n",
    "\n",
    "#创建训练集的数据加载器\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "#创建验证集的数据加载器\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "for noisy_imgs, clean_imgs in train_loader:\n",
    "    print(f'Noisy images batch shape: {noisy_imgs.shape}')\n",
    "    print(f'Clean images batch shape: {clean_imgs.shape}')\n",
    "    break\n",
    "\n",
    "print('数据加载器创建完成，开始训练模型...')"
   ],
   "id": "56916debc1d3316e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------正在创建的数据集------------\n",
      "数据集创建完成，正在创建数据加载器...\n",
      "Noisy images batch shape: torch.Size([32, 3, 68, 68])\n",
      "Clean images batch shape: torch.Size([32, 3, 68, 68])\n",
      "数据加载器创建完成，开始训练模型...\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T12:01:04.553236600Z",
     "start_time": "2026-01-17T12:01:03.762401200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#设置训练的epoch数量\n",
    "num_epochs = 20\n",
    "#设置噪声因子，勇于向图像添加噪声\n",
    "noise_factor = 0.5\n",
    "model.to(device)  #将模型发送到指定设备（CPU或GPU）\n",
    "criterion = nn.MSELoss()\n",
    "# 定义优化器（关键：之前缺少这一步）\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "#optimizer.to(device)  错误代码\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  #设置模型为训练模式\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for noisy_imgs, clean_imgs in train_loader:\n",
    "        noisy_imgs = noisy_imgs.to(device)  #将数据发送到指定设备\n",
    "        clean_imgs = clean_imgs.to(device)\n",
    "\n",
    "        #前向传播\n",
    "        outputs = model(noisy_imgs)\n",
    "        loss = criterion(outputs, clean_imgs)\n",
    "\n",
    "        #反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * noisy_imgs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')"
   ],
   "id": "fb2e758ea52155f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 shape: torch.Size([32, 32, 68, 68])\n",
      "pool1 shape: torch.Size([32, 32, 34, 34])\n",
      "conv2 shape: torch.Size([32, 64, 34, 34])\n",
      "pool2 shape: torch.Size([32, 64, 17, 17])\n",
      "conv3 shape: torch.Size([32, 128, 17, 17])\n",
      "pool3 shape: torch.Size([32, 128, 8, 8])\n",
      "conv1 shape: torch.Size([32, 64, 8, 8])\n",
      "conv2 shape: torch.Size([32, 32, 8, 8])\n",
      "conv3 shape: torch.Size([32, 3, 8, 8])\n",
      "conv_out  shape: torch.Size([32, 3, 8, 8])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (68) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[52], line 21\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m#前向传播\u001B[39;00m\n\u001B[0;32m     20\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(noisy_imgs)\n\u001B[1;32m---> 21\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclean_imgs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m#反向传播和优化\u001B[39;00m\n\u001B[0;32m     24\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32m~\\.conda\\envs\\image_en\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1774\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1775\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\image_en\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1781\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1782\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1783\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1784\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1785\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1786\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1788\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1789\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\.conda\\envs\\image_en\\lib\\site-packages\\torch\\nn\\modules\\loss.py:634\u001B[0m, in \u001B[0;36mMSELoss.forward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m    631\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;124;03m    Runs the forward pass.\u001B[39;00m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 634\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmse_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\image_en\\lib\\site-packages\\torch\\nn\\functional.py:3864\u001B[0m, in \u001B[0;36mmse_loss\u001B[1;34m(input, target, size_average, reduce, reduction, weight)\u001B[0m\n\u001B[0;32m   3861\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3862\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[1;32m-> 3864\u001B[0m expanded_input, expanded_target \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbroadcast_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3866\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3867\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m weight\u001B[38;5;241m.\u001B[39msize() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize():\n",
      "File \u001B[1;32m~\\.conda\\envs\\image_en\\lib\\site-packages\\torch\\functional.py:77\u001B[0m, in \u001B[0;36mbroadcast_tensors\u001B[1;34m(*tensors)\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function(tensors):\n\u001B[0;32m     76\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(broadcast_tensors, tensors, \u001B[38;5;241m*\u001B[39mtensors)\n\u001B[1;32m---> 77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbroadcast_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The size of tensor a (8) must match the size of tensor b (68) at non-singleton dimension 3"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "25c5229865e628af"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
