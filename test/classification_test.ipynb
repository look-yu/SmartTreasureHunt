{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-21T09:24:38.307582200Z",
     "start_time": "2026-01-21T09:24:38.272278300Z"
    }
   },
   "source": [
    "'''from fontTools.misc.classifyTools import Classifier\n",
    "from sympy.tensor.tensor import tensor_mul\n",
    "\n",
    "classification_nmaes={\n",
    "    0: '上衣',\n",
    "    1: '鞋子',\n",
    "    2: '包',\n",
    "    3: '下衣',\n",
    "    4: '手表',\n",
    "}'''"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from fontTools.misc.classifyTools import Classifier\\nfrom sympy.tensor.tensor import tensor_mul\\n\\nclassification_nmaes={\\n    0: '上衣',\\n    1: '鞋子',\\n    2: '包',\\n    3: '下衣',\\n    4: '手表',\\n}\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T09:24:38.339582200Z",
     "start_time": "2026-01-21T09:24:38.309581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def sorted_alphanumeric(data):\n",
    "    import re\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(data, key=alphanum_key)\n",
    "\n",
    "#定义自定义数据集类FolderDataset\n",
    "class FolderDataset(Dataset):\n",
    "    def __init__(self,main_dir,transform=None):\n",
    "        self.root_dir=main_dir\n",
    "        self.transform=transform\n",
    "        self.all_image=sorted_alphanumeric(os.listdir(main_dir))\n",
    "        self.classification_nmaes=pd.read_csv('../common/fashion-labels.csv')\n",
    "        self.laberl_dict=dict(zip(self.classification_nmaes['id'],self.classification_nmaes['target']))  #拉链\n",
    "    def __len__(self):\n",
    "        return len(self.all_image)\n",
    "    def __getitem__(self,idx):\n",
    "        img_loc=os.path.join(self.root_dir,self.all_image[idx])\n",
    "\n",
    "        image=Image.open(img_loc).convert('RGB')\n",
    "        img_flag_id=self.labell_dict[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image=self.transform(image)\n",
    "        else:\n",
    "            raise RuntimeError(\"Transform is not defined\")\n",
    "        return tensor_image,img_flag_id\n",
    "'''"
   ],
   "id": "705fbfa9c24f6801",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import torch\\nfrom PIL import Image\\nimport torchvision.transforms as T\\nfrom torch.utils.data import Dataset\\nimport os\\nimport pandas as pd\\n\\ndef sorted_alphanumeric(data):\\n    import re\\n    convert = lambda text: int(text) if text.isdigit() else text.lower()\\n    alphanum_key = lambda key: [convert(c) for c in re.split(\\'([0-9]+)\\', key)]\\n    return sorted(data, key=alphanum_key)\\n\\n#定义自定义数据集类FolderDataset\\nclass FolderDataset(Dataset):\\n    def __init__(self,main_dir,transform=None):\\n        self.root_dir=main_dir\\n        self.transform=transform\\n        self.all_image=sorted_alphanumeric(os.listdir(main_dir))\\n        self.classification_nmaes=pd.read_csv(\\'../common/fashion-labels.csv\\')\\n        self.laberl_dict=dict(zip(self.classification_nmaes[\\'id\\'],self.classification_nmaes[\\'target\\']))  #拉链\\n    def __len__(self):\\n        return len(self.all_image)\\n    def __getitem__(self,idx):\\n        img_loc=os.path.join(self.root_dir,self.all_image[idx])\\n\\n        image=Image.open(img_loc).convert(\\'RGB\\')\\n        img_flag_id=self.labell_dict[idx]\\n\\n        if self.transform:\\n            image=self.transform(image)\\n        else:\\n            raise RuntimeError(\"Transform is not defined\")\\n        return tensor_image,img_flag_id\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T09:24:38.363320100Z",
     "start_time": "2026-01-21T09:24:38.340581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''import re\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "#检查是否有可用的GPU,否则使用CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "transforms=T.Compose([\n",
    "    T.Resize((64,64)),\n",
    "    T.ToTensor(),\n",
    "\n",
    "])\n",
    "print('----------正在创建数据表----------')\n",
    "full_dataset=FolderDataset('../common/dataset/', transform=transforms)\n",
    "train_size=int(0.75*len(full_dataset))\n",
    "val_size=len(full_dataset)-train_size\n",
    "full_dataset,val_size=torch.utils.data.random_split(full_dataset,[train_size,val_size])\n",
    "\n",
    "\n",
    "print('----------数据表创建完成----------')\n",
    "print('----------正在创建数据加载器----------')\n",
    "\n",
    "#定义批次大小\n",
    "batch=32\n",
    "\n",
    "#创建训练集的DataLoder,批次大小为32\n",
    "train_loder=torch.utils.data.DataLoader(full_dataset,batch_size=batch,shuffle=True)\n",
    "#创建验证集的DataLoder,批次大小为32\n",
    "val_loader=torch.utils.data.DataLoader(val_size,batch_size=batch)\n",
    "\n",
    "#创建完整集的DataLoder,批次大小为32\n",
    "full_loder=torch.utils.data.DataLoader(full_dataset,batch_size=batch)\n",
    "\n",
    "print('----------数据加载器创建完成----------')\n",
    "\n",
    "#遍历训练集的DataLoder，打印每第一个批次的数据\n",
    "for x,y in train_loder:\n",
    "    print('图像张量形状:',x.shape)\n",
    "    print('标签:',y.shape)\n",
    "    break\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "7e806f90f07b41a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import re\\nimport torch\\nimport torchvision.transforms as T\\n#检查是否有可用的GPU,否则使用CPU\\nif torch.cuda.is_available():\\n    device = torch.device(\"cuda\")\\nelse:\\n    device = torch.device(\"cpu\")\\ntransforms=T.Compose([\\n    T.Resize((64,64)),\\n    T.ToTensor(),\\n\\n])\\nprint(\\'----------正在创建数据表----------\\')\\nfull_dataset=FolderDataset(\\'../common/dataset/\\', transform=transforms)\\ntrain_size=int(0.75*len(full_dataset))\\nval_size=len(full_dataset)-train_size\\nfull_dataset,val_size=torch.utils.data.random_split(full_dataset,[train_size,val_size])\\n\\n\\nprint(\\'----------数据表创建完成----------\\')\\nprint(\\'----------正在创建数据加载器----------\\')\\n\\n#定义批次大小\\nbatch=32\\n\\n#创建训练集的DataLoder,批次大小为32\\ntrain_loder=torch.utils.data.DataLoader(full_dataset,batch_size=batch,shuffle=True)\\n#创建验证集的DataLoder,批次大小为32\\nval_loader=torch.utils.data.DataLoader(val_size,batch_size=batch)\\n\\n#创建完整集的DataLoder,批次大小为32\\nfull_loder=torch.utils.data.DataLoader(full_dataset,batch_size=batch)\\n\\nprint(\\'----------数据加载器创建完成----------\\')\\n\\n#遍历训练集的DataLoder，打印每第一个批次的数据\\nfor x,y in train_loder:\\n    print(\\'图像张量形状:\\',x.shape)\\n    print(\\'标签:\\',y.shape)\\n    break\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T09:24:38.400322400Z",
     "start_time": "2026-01-21T09:24:38.371320200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationModel,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=8,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
    "        self.pool=nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "        self.conv2=nn.Conv2d(in_channels=8,out_channels=16,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
    "        self.fc1=nn.Linear(16*16*16,128)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(x)\n",
    "\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=self.pool(x)\n",
    "\n",
    "        x=x.reshape(x.shape[0],-1)\n",
    "\n",
    "        x=self.fc1(x)\n",
    "        x=F.log_softmax(x,dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# 实例化CNN模型\n",
    "model=ClassificationModel()\n",
    "\n",
    "print(model)\n",
    "\n",
    "#获取训练加载器的迭代器\n",
    "train_iterator=iter(train_loder)\n",
    "#获取下一个批次的数据\n",
    "images,labels=next(train_iterator)\n",
    "print('数据经过模型后向前传递后的维度:',model(images).shape)\n",
    "'''"
   ],
   "id": "53f294ad1b8a4554",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import torch.nn as nn\\nimport torch.nn.functional as F\\n\\nclass ClassificationModel(nn.Module):\\n    def __init__(self):\\n        super(ClassificationModel,self).__init__()\\n        self.conv1=nn.Conv2d(in_channels=3,out_channels=8,kernel_size=(3,3),stride=(1,1),padding=(1,1))\\n        self.pool=nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\\n        self.conv2=nn.Conv2d(in_channels=8,out_channels=16,kernel_size=(3,3),stride=(1,1),padding=(1,1))\\n        self.fc1=nn.Linear(16*16*16,128)\\n\\n\\n    def forward(self,x):\\n        x=self.pool(F.relu(self.conv1(x)))\\n        x=self.pool(x)\\n\\n        x=self.pool(F.relu(self.conv2(x)))\\n        x=self.pool(x)\\n\\n        x=x.reshape(x.shape[0],-1)\\n\\n        x=self.fc1(x)\\n        x=F.log_softmax(x,dim=1)\\n        return x\\n\\n\\n\\n# 实例化CNN模型\\nmodel=ClassificationModel()\\n\\nprint(model)\\n\\n#获取训练加载器的迭代器\\ntrain_iterator=iter(train_loder)\\n#获取下一个批次的数据\\nimages,labels=next(train_iterator)\\nprint('数据经过模型后向前传递后的维度:',model(images).shape)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T09:24:38.422550800Z",
     "start_time": "2026-01-21T09:24:38.402319700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义一个字典，将数字标签映射为对应的中文名称\n",
    "classification_names = {\n",
    "    0: '上身衣服',  # 数字 0 对应“上身衣服”\n",
    "    1: '鞋',       # 数字 1 对应“鞋”\n",
    "    2: '包',       # 数字 2 对应“包”\n",
    "    3: '下身衣服',  # 数字 3 对应“下身衣服”\n",
    "    4: '手表'      # 数字 4 对应“手表”\n",
    "}"
   ],
   "id": "c5cc8a8027ed9964",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T09:24:43.100687700Z",
     "start_time": "2026-01-21T09:24:38.423549600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch  # 导入 PyTorch 库，用于深度学习任务\n",
    "from PIL import Image  # 导入 PIL 库中的 Image 模块，用于图像处理\n",
    "import os  # 导入 os 库，用于文件和目录操作\n",
    "from torch.utils.data import Dataset  # 导入 PyTorch 的 Dataset 类，用于创建自定义数据集\n",
    "import torchvision.transforms as T  # 导入 torchvision 的 transforms 模块，用于图像预处理\n",
    "import pandas as pd  # 导入 pandas 库，用于数据处理和分析\n",
    "\n",
    "def sorted_alphanumeric(data):\n",
    "    \"\"\"按字母数字混合顺序对文件名进行排序（例如：img1, img2, ..., img10）\"\"\"\n",
    "    # 定义转换函数：将数字部分转换为整数，非数字部分转换为小写\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    # 生成排序键：用正则分割字符串，分别处理数字和非数字部分\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    # 按生成的键排序\n",
    "    return sorted(data, key=alphanum_key)\n",
    "\n",
    "# 定义自定义数据集类 FolderDataset，继承自 PyTorch 的 Dataset 类\n",
    "class FolderDataset(Dataset):\n",
    "    def __init__(self, main_dir, transform=None):\n",
    "        \"\"\"\n",
    "        初始化方法。\n",
    "        :param main_dir: 图像文件夹的主路径\n",
    "        :param transform: 图像预处理操作（如缩放、裁剪、归一化等），默认为 None\n",
    "        \"\"\"\n",
    "        self.main_dir = main_dir  # 存储主目录路径\n",
    "        self.transform = transform  # 存储图像预处理操作\n",
    "        self.all_imgs = sorted_alphanumeric(os.listdir(main_dir))  # 获取主目录下的所有图像文件名\n",
    "        # 读取包含分类标签的 CSV 文件\n",
    "        self.classifications = pd.read_csv('../common/fashion-labels.csv')  # 从指定路径加载 CSV 文件到 DataFrame\n",
    "        # 将数据类型转换为字典，提升查询效率\n",
    "        self.label_dict = dict(zip(self.classifications['id'], self.classifications['target']))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集中图像的数量。\n",
    "        \"\"\"\n",
    "        return len(self.all_imgs)  # 返回图像文件的总数\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        根据索引 idx 获取图像及其标签。\n",
    "        :param idx: 图像的索引\n",
    "        :return: 预处理后的图像张量和对应的标签\n",
    "        \"\"\"\n",
    "        # print(\"index: \", idx)\n",
    "        img_loc = os.path.join(self.main_dir, self.all_imgs[idx])  # 获取第 idx 张图像的完整路径\n",
    "        image = Image.open(img_loc).convert(\"RGB\")  # 打开图像并将其转换为 RGB 格式\n",
    "        img_flag_id = self.label_dict[idx]  # 在分类数据中查找对应的标签\n",
    "\n",
    "        # 对图像进行预处理（如果定义了 transform）\n",
    "        if self.transform is not None:\n",
    "            tensor_image = self.transform(image)  # 应用预处理操作，将图像转换为张量\n",
    "        else:\n",
    "            raise RuntimeError(\"transform参数不能为None，需指定预处理方法\")\n",
    "\n",
    "        return tensor_image, img_flag_id  # 返回图像张量和标签"
   ],
   "id": "79ab561d0cb9bebc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T09:24:43.545845Z",
     "start_time": "2026-01-21T09:24:43.102687400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import torch\n",
    "# 检查是否有可用的GPU，如果有则使用GPU，否则使用CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "# 定义数据预处理流程：将图像调整为64x64大小，并将其转换为Tensor\n",
    "transforms = T.Compose([T.Resize((64, 64)), T.ToTensor()])\n",
    "\n",
    "# 打印提示信息，表示正在创建数据集\n",
    "print(\"------------ 正在创建数据集 ------------\")\n",
    "# 使用FolderDataset类加载数据集，数据集路径为'./image_similarity/dataset/'，并应用定义好的预处理流程\n",
    "full_dataset = FolderDataset('../common/dataset/', transforms)\n",
    "\n",
    "# 计算训练集和验证集的大小，训练集占数据集的75%，验证集占剩余的25%\n",
    "train_size = int(0.75 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "# 使用random_split函数将数据集随机划分为训练集和验证集\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "# 打印提示信息，表示数据集已创建\n",
    "print(\"------------ 数据集创建完成 ------------\")\n",
    "\n",
    "# 打印提示信息，表示正在创建DataLoader\n",
    "print(\"------------ 创建数据加载器 ------------\")\n",
    "\n",
    "# 定义批次大小为32\n",
    "batch = 32\n",
    "\n",
    "# 创建训练集的DataLoader，批次大小为32，打乱数据顺序，并丢弃最后一个不完整的批次\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch, shuffle=True, drop_last=True\n",
    ")\n",
    "\n",
    "# 创建验证集的DataLoader，批次大小为32，不打乱数据顺序\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch\n",
    ")\n",
    "\n",
    "# 创建完整数据集的DataLoader，批次大小为32，不打乱数据顺序\n",
    "full_loader = torch.utils.data.DataLoader(\n",
    "    full_dataset, batch_size=batch\n",
    ")\n",
    "\n",
    "print(\"------------ 数据加载器创建完成 ------------\")\n",
    "\n",
    "# 遍历训练集的DataLoader，获取第一个批次的数据并打印其形状\n",
    "for (x, y) in train_loader:\n",
    "    print(x.shape)  # 打印输入数据的形状\n",
    "    print(y.shape)  # 打印标签数据的形状\n",
    "    break  # 获取第一个批次后退出循环"
   ],
   "id": "7be9dbb1e07cb5ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ 正在创建数据集 ------------\n",
      "------------ 数据集创建完成 ------------\n",
      "------------ 创建数据加载器 ------------\n",
      "------------ 数据加载器创建完成 ------------\n",
      "torch.Size([32, 3, 64, 64])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T09:24:44.342080500Z",
     "start_time": "2026-01-21T09:24:43.546867100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn  # 导入 PyTorch 的神经网络模块，用于构建神经网络\n",
    "import torch.nn.functional as F  # 导入 PyTorch 的函数模块，包含激活函数、损失函数等\n",
    "\n",
    "'''class Classifier(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=5):\n",
    "        super(Classification, self).__init__()\n",
    "        # 定义第一个卷积层，输入通道数为3，输出通道数为8，卷积核大小为3x3，步幅为1，填充为1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        # 使用填充为1的卷积操作，输出特征图的尺寸与输入相同（Same convolutions）\n",
    "\n",
    "        # 定义最大池化层，池化核大小为2x2，步幅为2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        # 定义第二个卷积层，输入通道数为8，输出通道数为16，卷积核大小为3x3，步幅为1，填充为1\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        # 上一层的输出通道数为8，因此这一层的输入通道数为8\n",
    "\n",
    "        # 定义全连接层，输入大小为16*16*16，输出大小为num_classes（分类数）\n",
    "        self.fc1 = nn.Linear(16*16*16, num_classes)\n",
    "        # 输入大小为16是因为conv2的输出通道数为16，16*16是因为经过两次池化后，特征图的尺寸为16x16\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 第一层卷积 + ReLU激活函数\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # print(\"经过第一层卷积和ReLU激活函数后的维度：\", x.shape)\n",
    "        # 池化操作\n",
    "        x = self.pool(x)\n",
    "        # print(\"经过第一层池化后的维度：\", x.shape)\n",
    "        # 第二层卷积 + ReLU激活函数\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # print(\"经过第二层卷积和ReLU激活函数后的维度：\", x.shape)\n",
    "        # 池化操作\n",
    "        x = self.pool(x)\n",
    "        # print(\"经过第二层池化后的维度：\", x.shape)\n",
    "        # 将特征图展平为一维向量，保留batch_size维度，其余维度展平\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        # print(\"经过一维展平后的维度：\", x.shape)\n",
    "\n",
    "        # 全连接层\n",
    "        x = self.fc1(x)\n",
    "        # print(\"经过全连接层的维度：\", x.shape)\n",
    "\n",
    "        # 经过log_softmax处理后返回，该函数通常用于多分类任务\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        # print(\"经过log_softmax处理后的维度：\", x.shape)\n",
    "        return x\n",
    "\n",
    "# 实例化CNN模型\n",
    "model = Classifier()\n",
    "# 打印模型结构\n",
    "print(model)\n",
    "'''\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=5):\n",
    "        # 关键修正：把 Classification 改成 Classifier\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        # 修正：用参数 in_channels 统一输入通道数\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=8,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1)\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=8,\n",
    "            out_channels=16,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16*16*16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "# 实例化模型\n",
    "model = Classifier()\n",
    "# 打印模型结构\n",
    "print(model)\n",
    "\n",
    "# 获取训练数据加载器的迭代器\n",
    "it = iter(train_loader)\n",
    "# 获取下一个批次的数据\n",
    "X_batch, y_batch = next(it)\n",
    "# 打印模型前向传播输出的形状\n",
    "print(\"数据经过模型向前传递后的维度：\", model.forward(X_batch).shape)"
   ],
   "id": "441da067b0c19366",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=4096, out_features=5, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [8, 1, 3, 3], expected input[32, 3, 64, 64] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 97\u001B[0m\n\u001B[0;32m     95\u001B[0m X_batch, y_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(it)\n\u001B[0;32m     96\u001B[0m \u001B[38;5;66;03m# 打印模型前向传播输出的形状\u001B[39;00m\n\u001B[1;32m---> 97\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m数据经过模型向前传递后的维度：\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_batch\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshape)\n",
      "Cell \u001B[1;32mIn[8], line 78\u001B[0m, in \u001B[0;36mClassifier.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 78\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     79\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool(x)\n\u001B[0;32m     80\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x))\n",
      "File \u001B[1;32m~\\.conda\\envs\\Smart_Treasure_Hunt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Smart_Treasure_Hunt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\.conda\\envs\\Smart_Treasure_Hunt\\lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    547\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 548\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Smart_Treasure_Hunt\\lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    531\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(\n\u001B[0;32m    533\u001B[0m         F\u001B[38;5;241m.\u001B[39mpad(\n\u001B[0;32m    534\u001B[0m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    541\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups,\n\u001B[0;32m    542\u001B[0m     )\n\u001B[1;32m--> 543\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    544\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\n\u001B[0;32m    545\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Given groups=1, weight of size [8, 1, 3, 3], expected input[32, 3, 64, 64] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 指定损失函数为交叉熵损失函数，适用于多分类任务\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 指定优化器为Adam优化器，优化对象是模型的所有参数，学习率为0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 指定训练的轮数为20\n",
    "n_epochs = 20\n",
    "\n",
    "# 将模型移动到指定的设备（GPU或CPU）\n",
    "model.to(device)\n",
    "\n",
    "# 开始训练循环，遍历每个epoch\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # 初始化训练损失为0.0，用于累加每个批次的损失\n",
    "    train_loss = 0.0\n",
    "\n",
    "    ###################\n",
    "    # 训练模型 #\n",
    "    ###################\n",
    "    for (x, y) in train_loader:  # 遍历训练集的每个批次\n",
    "        # 将输入数据x和标签y移动到指定的设备（GPU或CPU）\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # 清除优化器中所有参数的梯度，避免梯度累积\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播：将输入数据x传递给模型，得到输出结果\n",
    "        output = model(x)\n",
    "        # 计算损失值，output是模型的预测结果，y是真实标签\n",
    "        loss = criterion(output, y)\n",
    "        # 反向传播：计算损失相对于模型参数的梯度\n",
    "        loss.backward()\n",
    "        # 更新模型参数：执行一次优化步骤\n",
    "        optimizer.step()\n",
    "        # 累加当前批次的损失值，乘以批次大小（x.size(0)）以得到总损失\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "    # 计算平均训练损失，总损失除以训练集的批次数量\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    # 打印当前epoch的训练损失\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
   ],
   "id": "9aa237b9d6bff868",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T09:27:16.254425100Z",
     "start_time": "2026-01-21T09:27:15.827309800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 导入matplotlib库用于绘图\n",
    "import matplotlib.pyplot as plt\n",
    "# 在Jupyter Notebook中内嵌显示matplotlib图像\n",
    "%matplotlib inline\n",
    "# 导入numpy库用于数值计算\n",
    "import numpy as np\n",
    "\n",
    "# 获取验证集的一个批次数据\n",
    "dataiter = iter(val_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# 将模型移动到CPU上，因为后续操作需要在CPU上执行\n",
    "model.to('cpu')\n",
    "\n",
    "# 获取模型对输入图像的输出结果\n",
    "output = model(images)\n",
    "# 将输出结果从计算图中分离，并转换为numpy数组\n",
    "output = output.detach().numpy()\n",
    "# 打印输出结果的形状\n",
    "print(output.shape)\n",
    "\n",
    "# 将输入图像从Tensor转换为numpy数组\n",
    "images = images.numpy()\n",
    "# 调整图像的维度顺序，从(C, H, W)变为(H, W, C)，以便matplotlib正确显示\n",
    "images = np.moveaxis(images, 1, -1)\n",
    "# 打印调整后的图像形状\n",
    "print(images.shape)\n",
    "\n",
    "# 遍历每个图像及其对应的模型输出结果\n",
    "for img, label in zip(images, output):\n",
    "    # 显示当前图像\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print(\"label: \", label)\n",
    "    print(\"label.shape: \", label.shape)\n",
    "    # 打印模型预测的类别名称\n",
    "    print(classification_names[np.argmax(label)])\n"
   ],
   "id": "ad56b3d76e0c3ded",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Matplotlib requires numpy>=1.23; you have 1.22.4",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 导入matplotlib库用于绘图\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# 在Jupyter Notebook中内嵌显示matplotlib图像\u001B[39;00m\n\u001B[0;32m      4\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatplotlib\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minline\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Smart_Treasure_Hunt\\lib\\site-packages\\matplotlib\\__init__.py:263\u001B[0m\n\u001B[0;32m    258\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m parse_version(module\u001B[38;5;241m.\u001B[39m__version__) \u001B[38;5;241m<\u001B[39m parse_version(minver):\n\u001B[0;32m    259\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMatplotlib requires \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m>=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mminver\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m; \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    260\u001B[0m                               \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou have \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 263\u001B[0m \u001B[43m_check_versions\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;66;03m# The decorator ensures this always returns the same handler (and it is only\u001B[39;00m\n\u001B[0;32m    267\u001B[0m \u001B[38;5;66;03m# attached once).\u001B[39;00m\n\u001B[0;32m    268\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mcache\n\u001B[0;32m    269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_ensure_handler\u001B[39m():\n",
      "File \u001B[1;32m~\\.conda\\envs\\Smart_Treasure_Hunt\\lib\\site-packages\\matplotlib\\__init__.py:259\u001B[0m, in \u001B[0;36m_check_versions\u001B[1;34m()\u001B[0m\n\u001B[0;32m    257\u001B[0m module \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(modname)\n\u001B[0;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parse_version(module\u001B[38;5;241m.\u001B[39m__version__) \u001B[38;5;241m<\u001B[39m parse_version(minver):\n\u001B[1;32m--> 259\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMatplotlib requires \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m>=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mminver\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m; \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    260\u001B[0m                       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou have \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mImportError\u001B[0m: Matplotlib requires numpy>=1.23; you have 1.22.4"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
