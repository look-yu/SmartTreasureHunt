{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-18T12:09:08.070506600Z",
     "start_time": "2026-01-18T12:09:07.506411800Z"
    }
   },
   "source": [
    "from fontTools.misc.classifyTools import Classifier\n",
    "from sympy.tensor.tensor import tensor_mul\n",
    "\n",
    "classification_nmaes={\n",
    "    0: '上衣',\n",
    "    1: '鞋子',\n",
    "    2: '包',\n",
    "    3: '下衣',\n",
    "    4: '手表',\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:09:11.991996800Z",
     "start_time": "2026-01-18T12:09:08.071506400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def sorted_alphanumeric(data):\n",
    "    import re\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(data, key=alphanum_key)\n",
    "\n",
    "#定义自定义数据集类FolderDataset\n",
    "class FolderDataset(Dataset):\n",
    "    def __init__(self,main_dir,transform=None):\n",
    "        self.root_dir=main_dir\n",
    "        self.transform=transform\n",
    "        self.all_image=sorted_alphanumeric(os.listdir(main_dir))\n",
    "        self.classification_nmaes=pd.read_csv('../common/fashion-labels.csv')\n",
    "        self.laberl_dict=dict(zip(self.classification_nmaes['id'],self.classification_nmaes['target']))  #拉链\n",
    "    def __len__(self):\n",
    "        return len(self.all_image)\n",
    "    def __getitem__(self,idx):\n",
    "        img_loc=os.path.join(self.root_dir,self.all_image[idx])\n",
    "\n",
    "        image=Image.open(img_loc).convert('RGB')\n",
    "        img_flag_id=self.labell_dict[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image=self.transform(image)\n",
    "        else:\n",
    "            raise RuntimeError(\"Transform is not defined\")\n",
    "        return tensor_image,img_flag_id\n"
   ],
   "id": "705fbfa9c24f6801",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T07:02:23.925838200Z",
     "start_time": "2026-01-20T07:02:17.564549500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "#检查是否有可用的GPU,否则使用CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "transforms=T.Compose([\n",
    "    T.Resize((64,64)),\n",
    "    T.ToTensor(),\n",
    "\n",
    "])\n",
    "print('----------正在创建数据表----------')\n",
    "full_dataset=FolderDataset('../common/dataset/', transform=transforms)\n",
    "train_size=int(0.75*len(full_dataset))\n",
    "val_size=len(full_dataset)-train_size\n",
    "full_dataset,val_size=torch.utils.data.random_split(full_dataset,[train_size,val_size])\n",
    "\n",
    "\n",
    "print('----------数据表创建完成----------')\n",
    "print('----------正在创建数据加载器----------')\n",
    "\n",
    "#定义批次大小\n",
    "batch=32\n",
    "\n",
    "#创建训练集的DataLoder,批次大小为32\n",
    "train_loder=torch.utils.data.DataLoader(full_dataset,batch_size=batch,shuffle=True)\n",
    "#创建验证集的DataLoder,批次大小为32\n",
    "val_loader=torch.utils.data.DataLoader(val_size,batch_size=batch)\n",
    "\n",
    "#创建完整集的DataLoder,批次大小为32\n",
    "full_loder=torch.utils.data.DataLoader(full_dataset,batch_size=batch)\n",
    "\n",
    "print('----------数据加载器创建完成----------')\n",
    "\n",
    "#遍历训练集的DataLoder，打印每第一个批次的数据\n",
    "for x,y in train_loder:\n",
    "    print('图像张量形状:',x.shape)\n",
    "    print('标签:',y.shape)\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "7e806f90f07b41a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------正在创建数据表----------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'FolderDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 15\u001B[0m\n\u001B[0;32m      9\u001B[0m transforms\u001B[38;5;241m=\u001B[39mT\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[0;32m     10\u001B[0m     T\u001B[38;5;241m.\u001B[39mResize((\u001B[38;5;241m64\u001B[39m,\u001B[38;5;241m64\u001B[39m)),\n\u001B[0;32m     11\u001B[0m     T\u001B[38;5;241m.\u001B[39mToTensor(),\n\u001B[0;32m     12\u001B[0m \n\u001B[0;32m     13\u001B[0m ])\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m----------正在创建数据表----------\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 15\u001B[0m full_dataset\u001B[38;5;241m=\u001B[39m\u001B[43mFolderDataset\u001B[49m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../common/dataset/\u001B[39m\u001B[38;5;124m'\u001B[39m, transform\u001B[38;5;241m=\u001B[39mtransforms)\n\u001B[0;32m     16\u001B[0m train_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mint\u001B[39m(\u001B[38;5;241m0.75\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlen\u001B[39m(full_dataset))\n\u001B[0;32m     17\u001B[0m val_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(full_dataset)\u001B[38;5;241m-\u001B[39mtrain_size\n",
      "\u001B[1;31mNameError\u001B[0m: name 'FolderDataset' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationModel,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=8,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
    "        self.pool=nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "        self.conv2=nn.Conv2d(in_channels=8,out_channels=16,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
    "        self.fc1=nn.Linear(16*16*16,128)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(x)\n",
    "\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=self.pool(x)\n",
    "\n",
    "        x=x.reshape(x.shape[0],-1)\n",
    "\n",
    "        x=self.fc1(x)\n",
    "        x=F.log_softmax(x,dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# 实例化CNN模型\n",
    "model=ClassificationModel()\n",
    "\n",
    "print(model)\n",
    "\n",
    "#获取训练加载器的迭代器\n",
    "train_iterator=iter(train_loder)\n",
    "#获取下一个批次的数据\n",
    "images,labels=next(train_iterator)\n",
    "print('数据经过模型后向前传递后的维度:',model(images).shape)"
   ],
   "id": "53f294ad1b8a4554",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
